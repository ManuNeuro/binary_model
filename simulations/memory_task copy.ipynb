{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e60ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2012-2023, NECOTIS\n",
    "# All rights reserved.\n",
    "#\n",
    "# Redistribution and use in source and binary forms, with or without modification,\n",
    "# are permitted provided that the following conditions are met:\n",
    "#\n",
    "#  - Redistributions of source code must retain the above copyright notice,\n",
    "#    this list of conditions and the following disclaimer.\n",
    "#  - Redistributions in binary form must reproduce the above copyright notice,\n",
    "#    this list of conditions and the following disclaimer in the documentation\n",
    "#    and/or other materials provided with the distribution.\n",
    "#  - Neither the name of the copyright holder nor the names of its contributors\n",
    "#    may be used to endorse or promote products derived from this software\n",
    "#    without specific prior written permission.\n",
    "#\n",
    "# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND\n",
    "# ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED\n",
    "# WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.\n",
    "# IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT,\n",
    "# INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT\n",
    "# NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA,\n",
    "# OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,\n",
    "# WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)\n",
    "# ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE\n",
    "# POSSIBILITY OF SUCH DAMAGE.\n",
    "\n",
    "# Authors: Emmanuel Calvet, Jean Rouat, Bertrand Reulet (advisor)\n",
    "# Date: July 07th, 2023\n",
    "# Organization: Groupe de recherche en Neurosciences Computationnelles et Traitement Intelligent des Signaux (NECOTIS),\n",
    "# Universit√© de Sherbrooke, Canada\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc520fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library and models\n",
    "# NB: you need to import binary_model into the python path\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Standard library\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# The model\n",
    "from tasks.whitenoise import whiteNoiseGauss\n",
    "from model.binaryModel import binaryModel\n",
    "from model.utils import (initRandomArchitecture, \n",
    "                        initGaussianWeights, dataPath,\n",
    "                        dataPathPerf, my_corrcoef, rescale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The experiment\n",
    "sim = 'performance_task'\n",
    "experiment = 'memory_white-noise'\n",
    "\n",
    "N = 10000\n",
    "duration = 2000\n",
    "nb_reservoir = 100 # Number of reservoir par value o sigma\n",
    "nb_trial = 5 # Number of different state initialization of the same reservoir\n",
    "K = 16 # Connectivity degree of the graph \n",
    "meanWeight = -0.1 # Average weights for the normal distribution\n",
    "I = 0.2 # Fraction of up neural state (20%) at times t=0\n",
    "\n",
    "# List of standard deviation sigma (of the normal distribution)\n",
    "# Predefined sigmas close to the phase transitions\n",
    "if meanWeight<0:\n",
    "    sigmas = [0.01  , 0.0133, 0.0167, 0.02, 0.0233, 0.0267, 0.03  ,\n",
    "            0.0333, 0.0367, 0.04,  0.042, 0.044, 0.046, 0.048, 0.05, 0.052, 0.055, 0.057, 0.06, 0.061, \n",
    "            0.0622, 0.0644, 0.065,  0.066, 0.0665, 0.0667, 0.067, 0.0675, 0.068, 0.0685, \n",
    "            0.0689, 0.069, 0.0695, 0.07  , 0.0711, 0.0733, 0.0756, 0.0778, 0.08  , 0.085 ,\n",
    "            0.09  , 0.1   , 0.11  , 0.13  , 0.14  , 0.15  , 0.2   , 0.3   ,\n",
    "            0.4   , 0.45  , 0.5   , 0.55  , 0.65  , 0.8   , 0.95  , 1.    ,\n",
    "            2.    ] \n",
    "elif meanWeight>0:\n",
    "    sigmas = [0.08 , 0.1  , 0.12 , 0.15 , 0.16 , 0.2  , 0.24 , 0.28 , 0.3  ,\n",
    "            0.32 , 0.35 , 0.36 , 0.37 , 0.38 , 0.392, 0.4  , 0.42 , 0.44 ,\n",
    "            0.45 , 0.48 , 0.5  , 0.52 , 0.56 , 0.6  , 0.62 , 0.64 , 0.68 ,\n",
    "            0.7  , 0.72 , 0.76 , 0.8  , 0.84 , 0.88 , 0.9  , 0.92 , 0.96 ,\n",
    "            1.   , 1.2  , 1.5  , 2.   ]\n",
    "\n",
    "# Values for testing purpose\n",
    "#nb_sigmas = 2\n",
    "#exponents = np.linspace(-2, 2, nb_sigmas)\n",
    "#sigmas = np.power(10, exponents)\n",
    "\n",
    "print(f'The model will be evaluated on {len(sigmas)} values of sigma(W):')\n",
    "print('sigma(W) =', sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = meanWeight\n",
    "# Parameters of the task --------------------------------------\n",
    "delays = [-10, -2]#[-18, -14, -10, -6, -2] # Parameter controlling difficulty of the memory task\n",
    "\n",
    "# Parameter of the training -----------------------------\n",
    "nbSample = 4000 # Number sample for the white-noise time serie\n",
    "tTrain = nbSample #  Time of training\n",
    "nbtrial = 5 # Number of trial for the training and tasks\n",
    "tDiscard = 500 # Discard 500 time step of transient\n",
    "tConv = 0 \n",
    "optionData = {'spikeCount': False, 'indexActive': False} \n",
    "kwargs = {'optionRun':optionData} # kwargs for the experiment\n",
    "\n",
    "# Parameters of the network -----------------------------\n",
    "inSize = 1 # Number of input neurons\n",
    "outSize = 1 # Number of output neurons\n",
    "I = 0.5 # Proportion of neuron of the reservoir to which the input/output is connected\n",
    "output_option =  'exclusion' # Option to obtain a non-overlapping set of neurons connected to input and readout\n",
    "kwargsOut = {'option':output_option,\n",
    "            'I':I}\n",
    "\n",
    "# Options of the readout --------------------------------\n",
    "learning = 'online'\n",
    "epoch = 4000\n",
    "optimizer = 'pytorch' \n",
    "activation = 'sigmoid'\n",
    "optim = 'adam'\n",
    "loss = 'MSE'\n",
    "scheduler = False\n",
    "alpha = 0.001\n",
    "\n",
    "if 'ridge' in optimizer:\n",
    "    kwargs.update({'beta':1E-08})\n",
    "elif optimizer == 'pseudoinverse':\n",
    "    kwargs.update({'activation':activation})\n",
    "kwargs.update({'optionCost':'mse'})\n",
    "if optimizer == 'ANN':\n",
    "    kwargs.update({'alpha':1E-04,\n",
    "                    'nbiter':epoch,\n",
    "                    'activation':activation})\n",
    "elif optimizer == 'pytorch':\n",
    "    kwargs.update({'optionOptim':{'alpha':alpha,\n",
    "                        'epoch':epoch,\n",
    "                        'activation':activation,\n",
    "                        'optim':optim,\n",
    "                        'loss':loss,\n",
    "                        'scheduler':scheduler,\n",
    "                        }\n",
    "            })\n",
    "\n",
    "tag = f\"{experiment}_{optimizer}_{activation}_output-{output_option}\"\n",
    "\n",
    "# Dictionary of result ---------------------------------\n",
    "path = dataPathPerf(sim, experiment, optimizer=optimizer, activation=activation, nbtrial=nb_trial)\n",
    "name = path+f'\\dicError_{tag}_nbReservoir{nb_reservoir}_N{N}_K{K}_W{mu}_T{nb_trial}'\n",
    "try:\n",
    "    dicResult = np.load(name+'.npy', allow_pickle='TRUE').item()\n",
    "    corr_delay = dicResult['corr']\n",
    "    infoReservoir = dicResult['infoReservoir']\n",
    "    print('File loaded:', name)\n",
    "except:\n",
    "    print('File not loaded, will create one:', name)\n",
    "    corr_delay = {delay: {} for delay in delays}\n",
    "    infoReservoir = {delay: {} for delay in delays}\n",
    "    dicResult = {'corr':corr_delay,\n",
    "                    'delay':delays,\n",
    "                    'nbtrial':nb_trial,\n",
    "                    'infoReservoir':infoReservoir,\n",
    "                    'inputs':'all',\n",
    "                    'optim': kwargs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58572f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "optionData = {'spikeCount':True, 'indexActive':False} # Option for saving data\n",
    "brain = binaryModel(N, sim=sim, experiment=experiment)\n",
    "seedConnectivity = 747\n",
    "initRandomArchitecture(brain, K, seed=seedConnectivity) # Fixed architecture\n",
    "print(kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e452b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run the experiment\n",
    "import glob\n",
    "\n",
    "for sigma in tqdm(sigmas):\n",
    "    sigma = np.round(sigma, 5)\n",
    "\n",
    "    for res_idx in range(nb_reservoir):\n",
    "        seed=res_idx*100\n",
    "        print(f'Reservoir #{res_idx}, sigma={sigma}')\n",
    "\n",
    "        # Initialize weights\n",
    "        initGaussianWeights(brain, mu, sigma, seed)\n",
    "\n",
    "        # Input neurons\n",
    "        optionIn = 'global'\n",
    "        kwargsIn = {}\n",
    "\n",
    "        # Input layer initialization\n",
    "        brain.addInputLayer(inSize=inSize, tag=tag)\n",
    "\n",
    "        # Readout initialization\n",
    "        brain.addReadoutLayer(outSize)\n",
    "        pathBrain = dataPathPerf(sim, experiment, optimizer=optimizer, \n",
    "                                 activation=activation, nbtrial=nb_trial)+f'/sigma{sigma}/seed{seed}'\n",
    "\n",
    "        # Check network has not been run already\n",
    "        dataFile = glob.glob(pathBrain+\"/metadata_\"+tag+f'*N{N}_K{K}*_W{meanWeight}_*.npy')\n",
    "        if len(dataFile) != 0:\n",
    "            print('Network already run, next...\\n \\n')\n",
    "            continue\n",
    "\n",
    "        # Select delay for the targets signals\n",
    "        for i, delay in enumerate(delays):\n",
    "            \n",
    "            # Initialize dictionary result \n",
    "            if corr_delay.get(delay, None) is None:\n",
    "                corr_delay.update({delay:{}})\n",
    "                infoReservoir.update({delay:{}})\n",
    "            if corr_delay[delay].get(sigma, None) is None:\n",
    "                corr_delay[delay].update({sigma:[]})\n",
    "                infoReservoir[delay].update({sigma:[]})\n",
    "\n",
    "            # Check if this task is already performed\n",
    "            print(f'delay={delay}, sigma={sigma}')\n",
    "            nb_reservoir_run = len(infoReservoir[delay][sigma])\n",
    "            print(nb_reservoir_run, 'already runned circuits')\n",
    "            if nb_reservoir_run >= nb_reservoir:\n",
    "                print(f'Networks for delay={delay}, sigma={sigma} already run, next...\\n \\n')\n",
    "                continue\n",
    "            elif (nb_reservoir_run < nb_reservoir) and (res_idx < nb_reservoir_run):\n",
    "                print(f'Network {res_idx} for delay={delay}, sigma={sigma} already run, next...\\n \\n')\n",
    "                continue\n",
    "            print('-----------------------------')\n",
    "            \n",
    "            # Initialize inputs and targets for training\n",
    "            datas = rescale(whiteNoiseGauss(2*nbSample))\n",
    "            y_train = datas[tDiscard+delay:nbSample+delay]\n",
    "            x_train = datas[:tTrain] # Input of the network\n",
    "            t_train = np.arange(0, tTrain)\n",
    "            inputs_train = [x_train, t_train]\n",
    "\n",
    "            corrTrials = [] # List to save performance (evulated by the correlation)\n",
    "            # Compute all trials\n",
    "            for k in range(nbtrial):\n",
    "                # Display information\n",
    "                print(f'Reservoir #{res_idx}, trial #{k}')\n",
    "                print('********************')\n",
    "                brain.displayInfoNetwork()\n",
    "                print('********************')    \n",
    "                print('White-noise, delay =', delay)\n",
    "\n",
    "                # Input layer initialization - multiple init\n",
    "                brain.setArchitectureIn(None, option=optionIn, I=I, seed=k*100, **kwargsIn)\n",
    "                brain.setWeightsIn(None, distribution='uniform', seed=k*100)\n",
    "                \n",
    "                # Readout initialization - multiple init\n",
    "                brain.setArchitectureOut(None, distribution='uniform', seed=k*100, **kwargsOut)\n",
    "\n",
    "                ##################################\n",
    "                # Training\n",
    "                ##################################\n",
    "                print('------------------------')\n",
    "                # Set input and target trains\n",
    "                u_train = [inputs_train]\n",
    "                y_train = [y_train]\n",
    "                \n",
    "                # TRAIN !\n",
    "                brain.train(u_trains = u_train,\n",
    "                            y_targets = y_train,\n",
    "                            I = I,\n",
    "                            duration = tTrain,\n",
    "                            discardTime = tDiscard,\n",
    "                            convergingTime = tConv,\n",
    "                            option = learning,\n",
    "                            optimizer = optimizer,\n",
    "                            tag = tag,\n",
    "                            **kwargs)\n",
    "                print('Mean weight out :', np.mean(brain.Wout), np.std(brain.Wout))\n",
    "                \n",
    "                ##################################\n",
    "                # Task on test set\n",
    "                ##################################\n",
    "                brain.reset()\n",
    "                brain.activationFunction(activation)\n",
    "                print('------------------------')\n",
    "                print('Task : white-noise on test data')\n",
    "                # test set fitting\n",
    "                datas = rescale(whiteNoiseGauss(2*nbSample))\n",
    "                y_test = datas[tDiscard+delay:nbSample+delay]\n",
    "                u_test = datas[:tTrain]\n",
    "                tTest = len(u_test)\n",
    "                t_test  = np.arange(0, tTest)\n",
    "                inputs = (u_test, t_test)\n",
    "                y_pred, err = brain.read(inputs, duration=tTest, I=I,\n",
    "                                discardTime=tDiscard, convergingTime=tConv,\n",
    "                                y_target=y_test, reset=True, tag=tag, **kwargs)\n",
    "                corrCoeff = my_corrcoef(y_pred, y_test)\n",
    "                \n",
    "                ##################################\n",
    "                # Performance and storing\n",
    "                ##################################\n",
    "                # Error for each tau of MG\n",
    "                print('Total error on that task :')\n",
    "                print('Corr_coeff =', corrCoeff)\n",
    "                corrTrials.append(corrCoeff)\n",
    "                print('Done')\n",
    "                print('------------------------')\n",
    "            print('==================================')\n",
    "            corr_delay[delay][sigma].append(corrTrials)\n",
    "            infoReservoir[delay][sigma].append(brain.metadata)\n",
    "            print(brain.metadata)\n",
    "\n",
    "        # Save metadata\n",
    "        tag_ = tag + f'_seed{seed}'\n",
    "        brain.saveData(path=pathBrain, tag=tag_)\n",
    "        brain.saveMetadata(path=pathBrain, tag=tag_)\n",
    "        brain.reset(deep=True)\n",
    "        \n",
    "        # Save result in a dictionary]\n",
    "        dicResult['corr'].update(corr_delay)\n",
    "        dicResult['infoReservoir'].update(infoReservoir)\n",
    "        np.save(name, dicResult)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e90d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format all results in a dataframe\n",
    "import pandas as pd\n",
    "from model.utils import save_df\n",
    "\n",
    "def make_csv_corr_vs_attractor(N, mu, K, nbtrial, nbReservoir, \n",
    "                               delays, output, optimizer, \n",
    "                               activation, sim='performance_task',\n",
    "                               experiment='prediction_mackey-glass'):\n",
    "    \n",
    "    # Save all results\n",
    "    result_dir = dataPathPerf(sim, experiment)\n",
    "    commonFolder = os.path.join(result_dir, 'allResults/')\n",
    "    if not os.path.isdir(commonFolder):\n",
    "        os.makedirs(commonFolder)\n",
    "    df_path = commonFolder + f'{experiment}_allReservoirs_N{N}_K{K}_W{mu}_T{nbtrial}'\n",
    "\n",
    "    path = dataPathPerf(sim, experiment, optimizer=optimizer,\n",
    "                        activation=activation, nbtrial=nbtrial)\n",
    "    \n",
    "    tag = f\"{experiment}_{optimizer}_{activation}_output-{output}\"\n",
    "    name = f'/dicError_{tag}_nbReservoir{nbReservoir}_N{N}_K{K}_W{mu}_T{nbtrial}.npy'\n",
    "\n",
    "    print(path+name)\n",
    "    dicResult = np.load(path+name, allow_pickle='TRUE').item()\n",
    "        \n",
    "    infoReservoirs = dicResult['infoReservoir']\n",
    "    corrReservoirs = dicResult['corr']\n",
    "    for delay in delays:\n",
    "        corrReservoir_sigma = corrReservoirs[delay]\n",
    "        infoReservoir_sigma = infoReservoirs[delay]\n",
    " \n",
    "        sigmas = []\n",
    "        seeds = []\n",
    "        corr_reservoirs = []\n",
    "        for n, (sigma, corr_list) in enumerate(corrReservoir_sigma.items()):\n",
    "            infoReservoir_list = infoReservoir_sigma[sigma]\n",
    "        \n",
    "            for i, corr in enumerate(corr_list[0:nbReservoir]):\n",
    "                \n",
    "                # Load data\n",
    "                infoReservoir = infoReservoir_list[i]\n",
    "                sigma = infoReservoir['stdWeights']\n",
    "                # Update results\n",
    "                sigmas.append(sigma)\n",
    "                seeds.append(seed)\n",
    "                corr = np.array(corr)\n",
    "                corr = corr[~np.isnan(corr)]\n",
    "                corr_reservoirs.append(np.mean(corr))\n",
    "                \n",
    "        # Create dictionary\n",
    "        dic_reservoir = {'stdWeights':sigmas,\n",
    "                       'seed':seeds,\n",
    "                       f'<C>, delay={delay}':corr_reservoirs,\n",
    "                       }\n",
    "        # Save csv\n",
    "        df = save_df(df_path, dic_reservoir)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = make_csv_corr_vs_attractor(N, mu, K, nb_trial, nb_reservoir, \n",
    "                               delays, output_option, optimizer, \n",
    "                               activation, sim=sim,\n",
    "                               experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3307b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "criticality",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "6cf55cd172315896cdf7658b4f32d3d4b894c1add34cfe6a00e99f05e4ae6e58"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
